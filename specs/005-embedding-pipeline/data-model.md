# Data Model: Embedding Pipeline Setup for RAG System

## Overview
This document defines the data models and structures for the embedding pipeline that crawls Docusaurus URLs, extracts text, generates Cohere embeddings, and stores them in Qdrant.

## Core Entities

### DocumentContent
- **Description**: Represents extracted content from a single Docusaurus page
- **Attributes**:
  - url (string): The source URL of the document
  - title (string): The page title extracted from HTML
  - content (string): The cleaned text content extracted from the page
  - metadata (dict): Additional metadata like headings, sections, etc.
  - created_at (datetime): Timestamp when content was extracted
  - updated_at (datetime): Timestamp when content was last updated

### TextChunk
- **Description**: A chunk of text content that will be embedded and stored in Qdrant
- **Attributes**:
  - id (string): Unique identifier for the chunk (URL + position)
  - content (string): The text content of the chunk (512-1024 tokens)
  - source_url (string): The original URL this chunk came from
  - source_title (string): The title of the original page
  - position (integer): The position of this chunk in the original document
  - metadata (dict): Additional metadata for the chunk
  - embedding (list[float]): The vector embedding (1024 dimensions)

### EmbeddingVector
- **Description**: A vector representation of a text chunk generated by Cohere
- **Attributes**:
  - vector_id (string): Unique identifier matching the TextChunk ID
  - vector (list[float]): The embedding vector (1024 dimensions)
  - model (string): The model used to generate the embedding
  - input_tokens (integer): Number of tokens in the original input
  - created_at (datetime): Timestamp when embedding was generated

### CrawlResult
- **Description**: Result of crawling a Docusaurus site
- **Attributes**:
  - start_url (string): The initial URL that started the crawl
  - discovered_urls (list[string]): All URLs discovered during crawling
  - processed_urls (list[string]): URLs that were successfully processed
  - failed_urls (list[string]): URLs that failed during processing
  - total_pages (integer): Total number of pages discovered
  - processed_pages (integer): Number of pages successfully processed
  - crawl_timestamp (datetime): When the crawl was initiated

## Qdrant Collection Schema

### rag-embedding Collection
- **Vector Dimensions**: 1024 (matching Cohere embedding size)
- **Distance Metric**: Cosine similarity

#### Payload Structure
- **content** (string): The text content of the chunk
- **source_url** (string): The original URL where this content was found
- **source_title** (string): The title of the original page
- **chunk_position** (integer): The position of this chunk in the original document
- **created_at** (datetime): When this embedding was created
- **metadata** (json): Additional metadata in JSON format

## Data Relationships

### DocumentContent -> TextChunk
- **Relationship**: One-to-Many
- **Cardinality**: One DocumentContent can be split into many TextChunks
- **Rule**: Each document is chunked based on content size and semantic boundaries

### TextChunk -> EmbeddingVector
- **Relationship**: One-to-One
- **Cardinality**: One TextChunk maps to exactly one EmbeddingVector
- **Rule**: Each chunk gets exactly one embedding vector generated

### CrawlResult -> DocumentContent
- **Relationship**: One-to-Many
- **Cardinality**: One crawl operation produces many DocumentContent items
- **Rule**: Each URL discovered in the crawl produces one DocumentContent

## Data Flow

### Ingestion Flow
1. **Crawling**: CrawlResult discovers URLs from the Docusaurus site
2. **Extraction**: Each URL produces one DocumentContent with full page content
3. **Chunking**: Each DocumentContent is split into multiple TextChunk items
4. **Embedding**: Each TextChunk generates one EmbeddingVector
5. **Storage**: EmbeddingVector and metadata are stored in Qdrant rag-embedding collection

### Access Flow
1. **Query**: User provides search query
2. **Embedding**: Query is converted to embedding vector using same model
3. **Search**: Qdrant performs similarity search in rag-embedding collection
4. **Retrieval**: Relevant TextChunks with metadata are returned
5. **Response**: Content is formatted for RAG application use

## Data Validation Rules

### DocumentContent Validation
- URL must be a valid HTTPS URL from the target domain
- Content must be non-empty after cleaning
- Title must be extracted successfully

### TextChunk Validation
- Content length must be between 100 and 2000 tokens
- Position must be non-negative integer
- Must have valid source reference

### EmbeddingVector Validation
- Vector must have exactly 1024 dimensions
- All values must be finite floats
- Must correspond to a valid TextChunk

### Qdrant Payload Validation
- Required fields (content, source_url, source_title) must be present
- Vector ID must match the expected format
- Metadata must be valid JSON

## Data Lifecycle

### Creation
- DocumentContent created during crawling phase
- TextChunk created during chunking phase
- EmbeddingVector created during embedding phase
- Qdrant record created during storage phase

### Update
- Content updates trigger re-processing of affected chunks
- Embeddings are regenerated when source content changes
- Qdrant records are updated with new embeddings

### Access Patterns
- Read-heavy for search and retrieval operations
- Batch writes during initial indexing
- Incremental updates for content changes

This data model provides the structure needed to implement the embedding pipeline with all specified functionality.